{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-16T12:42:00.852302Z","iopub.execute_input":"2023-03-16T12:42:00.852737Z","iopub.status.idle":"2023-03-16T12:42:00.879295Z","shell.execute_reply.started":"2023-03-16T12:42:00.852695Z","shell.execute_reply":"2023-03-16T12:42:00.878153Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dont-overfit-ii/sample_submission.csv\n/kaggle/input/dont-overfit-ii/train.csv\n/kaggle/input/dont-overfit-ii/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:42:21.180684Z","iopub.execute_input":"2023-03-16T12:42:21.181084Z","iopub.status.idle":"2023-03-16T12:42:21.975591Z","shell.execute_reply.started":"2023-03-16T12:42:21.181047Z","shell.execute_reply":"2023-03-16T12:42:21.974390Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dont-overfit-ii/train.csv')\ndf = df.drop('id',axis=1)\ny = df['target']\nX = df.drop('target',axis=1)\ntest = pd.read_csv('/kaggle/input/dont-overfit-ii/test.csv')\ntest.drop('id',axis=1,inplace=True)\nX_mean = X.mean(axis=1)\nX['mean']  = X_mean\ntest_mean = test.mean(axis=1)\ntest['mean'] = test_mean","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:43:14.858872Z","iopub.execute_input":"2023-03-16T12:43:14.859312Z","iopub.status.idle":"2023-03-16T12:43:16.446855Z","shell.execute_reply.started":"2023-03-16T12:43:14.859271Z","shell.execute_reply":"2023-03-16T12:43:16.445444Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"features = [ '16', '33', '43', '45', '52', '63', '65', '73', '90', '91', '117', '133', '134', '149', '189', '199', '217', '237', '258', '295']\nX1 = X[features]\ntest = test[features]\nprint(len(X1), len(test))","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:44:03.827533Z","iopub.execute_input":"2023-03-16T12:44:03.827962Z","iopub.status.idle":"2023-03-16T12:44:03.891800Z","shell.execute_reply.started":"2023-03-16T12:44:03.827924Z","shell.execute_reply":"2023-03-16T12:44:03.890512Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"250 19750\n","output_type":"stream"}]},{"cell_type":"code","source":"params = {}\nparams['random_state'] = 0\nparams['n_jobs'] = -1\nparams['C'] = 0.126\nparams['penalty'] = 'l1'\nparams['class_weight'] = 'balance'\nparams['solver'] = 'saga'\nbest = params","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:44:27.305150Z","iopub.execute_input":"2023-03-16T12:44:27.305567Z","iopub.status.idle":"2023-03-16T12:44:27.311954Z","shell.execute_reply.started":"2023-03-16T12:44:27.305528Z","shell.execute_reply":"2023-03-16T12:44:27.310589Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train(X1, y, best):\n    folds = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 20, random_state = 0)\n    oof =  np.zeros(len(X1))\n    clfs = []\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X1, y)):\n            #print('--- Fold {} started at {}'.format(n_fold, time.ctime()))\n\n            train_x, train_y = X1.iloc[train_idx], y.iloc[train_idx]\n            valid_x, valid_y = X1.iloc[valid_idx], y.iloc[valid_idx]\n\n            clf = LogisticRegression(**best)\n            clf.fit(train_x, train_y)\n            clfs.append(clf)\n            \n            oof[valid_idx] += clf.predict_proba(valid_x)[:,1]\n            \n    return clfs, oof","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:44:44.228488Z","iopub.execute_input":"2023-03-16T12:44:44.228934Z","iopub.status.idle":"2023-03-16T12:44:44.237638Z","shell.execute_reply.started":"2023-03-16T12:44:44.228895Z","shell.execute_reply":"2023-03-16T12:44:44.236157Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def predict(clfs,test):\n    predictions = np.zeros(len(test))\n    for c in clfs:\n        predictions += c.predict_proba(test)[:,1]\n    predictions = predictions/len(clfs)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:45:45.710827Z","iopub.execute_input":"2023-03-16T12:45:45.711337Z","iopub.status.idle":"2023-03-16T12:45:45.717127Z","shell.execute_reply.started":"2023-03-16T12:45:45.711293Z","shell.execute_reply":"2023-03-16T12:45:45.716066Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"clfs, oof = train(X1 ,y, best)\nroc_auc_score(y, oof/20)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:46:02.532130Z","iopub.execute_input":"2023-03-16T12:46:02.532550Z","iopub.status.idle":"2023-03-16T12:46:13.190537Z","shell.execute_reply.started":"2023-03-16T12:46:02.532513Z","shell.execute_reply":"2023-03-16T12:46:13.189398Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.5859228447924313"},"metadata":{}}]},{"cell_type":"code","source":"predicitons =  predict(clfs,test)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:46:22.266175Z","iopub.execute_input":"2023-03-16T12:46:22.266623Z","iopub.status.idle":"2023-03-16T12:46:22.714290Z","shell.execute_reply.started":"2023-03-16T12:46:22.266583Z","shell.execute_reply":"2023-03-16T12:46:22.712588Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"result = pd.read_csv('/kaggle/input/dont-overfit-ii/sample_submission.csv')\nresult['target'] = predicitons\nresult.to_csv('submission13.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:46:53.769827Z","iopub.execute_input":"2023-03-16T12:46:53.770331Z","iopub.status.idle":"2023-03-16T12:46:53.842854Z","shell.execute_reply.started":"2023-03-16T12:46:53.770286Z","shell.execute_reply":"2023-03-16T12:46:53.841710Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential, load_model\nfrom keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\nfrom keras.optimizers import Adam\nfrom keras.utils import plot_model\n#from keras import *\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:57:20.643281Z","iopub.execute_input":"2023-03-16T12:57:20.644400Z","iopub.status.idle":"2023-03-16T12:57:20.649851Z","shell.execute_reply.started":"2023-03-16T12:57:20.644354Z","shell.execute_reply":"2023-03-16T12:57:20.648483Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#pip install keras\nimport keras","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:57:16.715801Z","iopub.execute_input":"2023-03-16T12:57:16.716247Z","iopub.status.idle":"2023-03-16T12:57:16.721000Z","shell.execute_reply.started":"2023-03-16T12:57:16.716211Z","shell.execute_reply":"2023-03-16T12:57:16.719948Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"es_callback = keras.callbacks.EarlyStopping(monitor='auc', patience=80)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:57:26.047160Z","iopub.execute_input":"2023-03-16T12:57:26.047579Z","iopub.status.idle":"2023-03-16T12:57:26.053464Z","shell.execute_reply.started":"2023-03-16T12:57:26.047542Z","shell.execute_reply":"2023-03-16T12:57:26.052402Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(keras.layers.Dense(16, activation='relu', input_dim=len(features)))\nmodel.add(keras.layers.Dropout(0.4))\nmodel.add(keras.layers.Dense(8, activation='relu'))\nmodel.add(keras.layers.Dropout(0.4))\n\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(X1,y,batch_size=40, \n                    epochs=290, validation_split=0.25, shuffle=True, callbacks=[es_callback])","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:57:51.169219Z","iopub.execute_input":"2023-03-16T12:57:51.169651Z","iopub.status.idle":"2023-03-16T12:58:06.776881Z","shell.execute_reply.started":"2023-03-16T12:57:51.169597Z","shell.execute_reply":"2023-03-16T12:58:06.775713Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/290\n5/5 [==============================] - 1s 62ms/step - loss: 0.8167 - accuracy: 0.5775 - val_loss: 0.7550 - val_accuracy: 0.5397\nEpoch 2/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.8074 - accuracy: 0.5615 - val_loss: 0.7490 - val_accuracy: 0.5556\nEpoch 3/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.8102 - accuracy: 0.5775 - val_loss: 0.7443 - val_accuracy: 0.5714\nEpoch 4/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.7567 - accuracy: 0.5936 - val_loss: 0.7404 - val_accuracy: 0.5714\nEpoch 5/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6948 - accuracy: 0.6150 - val_loss: 0.7375 - val_accuracy: 0.5873\nEpoch 6/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.7130 - accuracy: 0.6150 - val_loss: 0.7347 - val_accuracy: 0.6032\nEpoch 7/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.7819 - accuracy: 0.5775 - val_loss: 0.7325 - val_accuracy: 0.6032\nEpoch 8/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6638 - accuracy: 0.6791 - val_loss: 0.7307 - val_accuracy: 0.6190\nEpoch 9/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.7482 - accuracy: 0.6043 - val_loss: 0.7288 - val_accuracy: 0.6190\nEpoch 10/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.7681 - accuracy: 0.6203 - val_loss: 0.7264 - val_accuracy: 0.6349\nEpoch 11/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.6845 - val_loss: 0.7236 - val_accuracy: 0.6349\nEpoch 12/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.7005 - accuracy: 0.6738 - val_loss: 0.7213 - val_accuracy: 0.6508\nEpoch 13/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6685 - accuracy: 0.6791 - val_loss: 0.7199 - val_accuracy: 0.6508\nEpoch 14/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.7152 - accuracy: 0.6631 - val_loss: 0.7196 - val_accuracy: 0.6508\nEpoch 15/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6256 - accuracy: 0.7219 - val_loss: 0.7197 - val_accuracy: 0.6508\nEpoch 16/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6096 - accuracy: 0.6845 - val_loss: 0.7199 - val_accuracy: 0.6667\nEpoch 17/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6778 - accuracy: 0.6310 - val_loss: 0.7198 - val_accuracy: 0.6825\nEpoch 18/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.6684 - val_loss: 0.7194 - val_accuracy: 0.6825\nEpoch 19/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.7112 - val_loss: 0.7181 - val_accuracy: 0.6825\nEpoch 20/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.7177 - accuracy: 0.6898 - val_loss: 0.7172 - val_accuracy: 0.6825\nEpoch 21/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6052 - accuracy: 0.6952 - val_loss: 0.7167 - val_accuracy: 0.6825\nEpoch 22/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.6421 - accuracy: 0.7059 - val_loss: 0.7168 - val_accuracy: 0.6825\nEpoch 23/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5799 - accuracy: 0.7059 - val_loss: 0.7170 - val_accuracy: 0.6667\nEpoch 24/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6443 - accuracy: 0.6845 - val_loss: 0.7165 - val_accuracy: 0.6825\nEpoch 25/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6597 - accuracy: 0.6898 - val_loss: 0.7167 - val_accuracy: 0.6825\nEpoch 26/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5820 - accuracy: 0.7005 - val_loss: 0.7175 - val_accuracy: 0.6825\nEpoch 27/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5880 - accuracy: 0.7326 - val_loss: 0.7182 - val_accuracy: 0.6825\nEpoch 28/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5923 - accuracy: 0.7005 - val_loss: 0.7187 - val_accuracy: 0.6667\nEpoch 29/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6180 - accuracy: 0.7273 - val_loss: 0.7187 - val_accuracy: 0.6667\nEpoch 30/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.7166 - val_loss: 0.7192 - val_accuracy: 0.6667\nEpoch 31/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6297 - accuracy: 0.7059 - val_loss: 0.7193 - val_accuracy: 0.6667\nEpoch 32/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6140 - accuracy: 0.7326 - val_loss: 0.7189 - val_accuracy: 0.6667\nEpoch 33/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6043 - accuracy: 0.7112 - val_loss: 0.7184 - val_accuracy: 0.6667\nEpoch 34/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5956 - accuracy: 0.7487 - val_loss: 0.7181 - val_accuracy: 0.6667\nEpoch 35/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6181 - accuracy: 0.6952 - val_loss: 0.7183 - val_accuracy: 0.6667\nEpoch 36/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.6898 - val_loss: 0.7185 - val_accuracy: 0.6667\nEpoch 37/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.6086 - accuracy: 0.7005 - val_loss: 0.7193 - val_accuracy: 0.6667\nEpoch 38/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5824 - accuracy: 0.7594 - val_loss: 0.7199 - val_accuracy: 0.6667\nEpoch 39/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.6845 - val_loss: 0.7197 - val_accuracy: 0.6667\nEpoch 40/290\n5/5 [==============================] - 0s 13ms/step - loss: 0.5970 - accuracy: 0.7166 - val_loss: 0.7186 - val_accuracy: 0.6667\nEpoch 41/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5706 - accuracy: 0.7112 - val_loss: 0.7179 - val_accuracy: 0.6667\nEpoch 42/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6210 - accuracy: 0.7166 - val_loss: 0.7176 - val_accuracy: 0.6667\nEpoch 43/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.6046 - accuracy: 0.7326 - val_loss: 0.7179 - val_accuracy: 0.6667\nEpoch 44/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5533 - accuracy: 0.7166 - val_loss: 0.7182 - val_accuracy: 0.6825\nEpoch 45/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5878 - accuracy: 0.7273 - val_loss: 0.7184 - val_accuracy: 0.6825\nEpoch 46/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5412 - accuracy: 0.7166 - val_loss: 0.7189 - val_accuracy: 0.6825\nEpoch 47/290\n5/5 [==============================] - 0s 13ms/step - loss: 0.5783 - accuracy: 0.7112 - val_loss: 0.7189 - val_accuracy: 0.6825\nEpoch 48/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5060 - accuracy: 0.7540 - val_loss: 0.7196 - val_accuracy: 0.6825\nEpoch 49/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5667 - accuracy: 0.7380 - val_loss: 0.7211 - val_accuracy: 0.6825\nEpoch 50/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5337 - accuracy: 0.7433 - val_loss: 0.7221 - val_accuracy: 0.6825\nEpoch 51/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5418 - accuracy: 0.7380 - val_loss: 0.7236 - val_accuracy: 0.6825\nEpoch 52/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5780 - accuracy: 0.7005 - val_loss: 0.7248 - val_accuracy: 0.6825\nEpoch 53/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5443 - accuracy: 0.7487 - val_loss: 0.7254 - val_accuracy: 0.6825\nEpoch 54/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5649 - accuracy: 0.7273 - val_loss: 0.7253 - val_accuracy: 0.6825\nEpoch 55/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5417 - accuracy: 0.6952 - val_loss: 0.7258 - val_accuracy: 0.6825\nEpoch 56/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5409 - accuracy: 0.7273 - val_loss: 0.7267 - val_accuracy: 0.6825\nEpoch 57/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5680 - accuracy: 0.7166 - val_loss: 0.7275 - val_accuracy: 0.6825\nEpoch 58/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5383 - accuracy: 0.7487 - val_loss: 0.7285 - val_accuracy: 0.6825\nEpoch 59/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5596 - accuracy: 0.7219 - val_loss: 0.7287 - val_accuracy: 0.6825\nEpoch 60/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5382 - accuracy: 0.7647 - val_loss: 0.7288 - val_accuracy: 0.6825\nEpoch 61/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5610 - accuracy: 0.7273 - val_loss: 0.7293 - val_accuracy: 0.6825\nEpoch 62/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5561 - accuracy: 0.7540 - val_loss: 0.7294 - val_accuracy: 0.6825\nEpoch 63/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5415 - accuracy: 0.7219 - val_loss: 0.7298 - val_accuracy: 0.6825\nEpoch 64/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5633 - accuracy: 0.7487 - val_loss: 0.7307 - val_accuracy: 0.6825\nEpoch 65/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5214 - accuracy: 0.7433 - val_loss: 0.7316 - val_accuracy: 0.6825\nEpoch 66/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5797 - accuracy: 0.7487 - val_loss: 0.7315 - val_accuracy: 0.6825\nEpoch 67/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.7326 - val_loss: 0.7317 - val_accuracy: 0.6825\nEpoch 68/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5446 - accuracy: 0.7112 - val_loss: 0.7321 - val_accuracy: 0.6825\nEpoch 69/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5108 - accuracy: 0.7594 - val_loss: 0.7328 - val_accuracy: 0.6825\nEpoch 70/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5771 - accuracy: 0.7594 - val_loss: 0.7328 - val_accuracy: 0.6825\nEpoch 71/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5187 - accuracy: 0.7326 - val_loss: 0.7335 - val_accuracy: 0.6825\nEpoch 72/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4756 - accuracy: 0.7487 - val_loss: 0.7346 - val_accuracy: 0.6825\nEpoch 73/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5448 - accuracy: 0.7380 - val_loss: 0.7357 - val_accuracy: 0.6825\nEpoch 74/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5122 - accuracy: 0.7326 - val_loss: 0.7362 - val_accuracy: 0.6825\nEpoch 75/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5094 - accuracy: 0.7754 - val_loss: 0.7372 - val_accuracy: 0.6825\nEpoch 76/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5442 - accuracy: 0.7380 - val_loss: 0.7384 - val_accuracy: 0.6825\nEpoch 77/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5225 - accuracy: 0.7754 - val_loss: 0.7396 - val_accuracy: 0.6825\nEpoch 78/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5166 - accuracy: 0.7701 - val_loss: 0.7399 - val_accuracy: 0.6825\nEpoch 79/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5451 - accuracy: 0.7487 - val_loss: 0.7404 - val_accuracy: 0.6825\nEpoch 80/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5158 - accuracy: 0.7326 - val_loss: 0.7407 - val_accuracy: 0.6825\nEpoch 81/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4895 - accuracy: 0.7914 - val_loss: 0.7416 - val_accuracy: 0.6825\nEpoch 82/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5522 - accuracy: 0.7433 - val_loss: 0.7431 - val_accuracy: 0.6825\nEpoch 83/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7594 - val_loss: 0.7433 - val_accuracy: 0.6825\nEpoch 84/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5053 - accuracy: 0.7594 - val_loss: 0.7438 - val_accuracy: 0.6825\nEpoch 85/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5119 - accuracy: 0.7540 - val_loss: 0.7451 - val_accuracy: 0.6825\nEpoch 86/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5220 - accuracy: 0.7433 - val_loss: 0.7469 - val_accuracy: 0.6825\nEpoch 87/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5108 - accuracy: 0.7487 - val_loss: 0.7483 - val_accuracy: 0.6825\nEpoch 88/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5261 - accuracy: 0.7433 - val_loss: 0.7498 - val_accuracy: 0.6825\nEpoch 89/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5489 - accuracy: 0.7380 - val_loss: 0.7507 - val_accuracy: 0.6825\nEpoch 90/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5082 - accuracy: 0.7647 - val_loss: 0.7515 - val_accuracy: 0.6825\nEpoch 91/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5211 - accuracy: 0.7487 - val_loss: 0.7520 - val_accuracy: 0.6825\nEpoch 92/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5440 - accuracy: 0.7433 - val_loss: 0.7533 - val_accuracy: 0.6825\nEpoch 93/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4863 - accuracy: 0.7594 - val_loss: 0.7546 - val_accuracy: 0.6825\nEpoch 94/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5198 - accuracy: 0.7701 - val_loss: 0.7563 - val_accuracy: 0.6825\nEpoch 95/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.7433 - val_loss: 0.7575 - val_accuracy: 0.6825\nEpoch 96/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5268 - accuracy: 0.7540 - val_loss: 0.7591 - val_accuracy: 0.6825\nEpoch 97/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5149 - accuracy: 0.7487 - val_loss: 0.7619 - val_accuracy: 0.6825\nEpoch 98/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5098 - accuracy: 0.7807 - val_loss: 0.7633 - val_accuracy: 0.6825\nEpoch 99/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4852 - accuracy: 0.7914 - val_loss: 0.7647 - val_accuracy: 0.6825\nEpoch 100/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4837 - accuracy: 0.7594 - val_loss: 0.7671 - val_accuracy: 0.6825\nEpoch 101/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5416 - accuracy: 0.7487 - val_loss: 0.7687 - val_accuracy: 0.6825\nEpoch 102/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5031 - accuracy: 0.7433 - val_loss: 0.7702 - val_accuracy: 0.6825\nEpoch 103/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.7540 - val_loss: 0.7715 - val_accuracy: 0.6825\nEpoch 104/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4960 - accuracy: 0.7487 - val_loss: 0.7734 - val_accuracy: 0.6825\nEpoch 105/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.7380 - val_loss: 0.7756 - val_accuracy: 0.6825\nEpoch 106/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.7540 - val_loss: 0.7785 - val_accuracy: 0.6825\nEpoch 107/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5077 - accuracy: 0.7219 - val_loss: 0.7809 - val_accuracy: 0.6825\nEpoch 108/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5366 - accuracy: 0.7005 - val_loss: 0.7830 - val_accuracy: 0.6825\nEpoch 109/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5444 - accuracy: 0.7594 - val_loss: 0.7834 - val_accuracy: 0.6667\nEpoch 110/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4896 - accuracy: 0.7433 - val_loss: 0.7836 - val_accuracy: 0.6667\nEpoch 111/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4769 - accuracy: 0.7594 - val_loss: 0.7849 - val_accuracy: 0.6667\nEpoch 112/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.7594 - val_loss: 0.7858 - val_accuracy: 0.6825\nEpoch 113/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5214 - accuracy: 0.7540 - val_loss: 0.7860 - val_accuracy: 0.6825\nEpoch 114/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4619 - accuracy: 0.7701 - val_loss: 0.7877 - val_accuracy: 0.6667\nEpoch 115/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5069 - accuracy: 0.7380 - val_loss: 0.7894 - val_accuracy: 0.6667\nEpoch 116/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4943 - accuracy: 0.7701 - val_loss: 0.7907 - val_accuracy: 0.6667\nEpoch 117/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5047 - accuracy: 0.7540 - val_loss: 0.7917 - val_accuracy: 0.6667\nEpoch 118/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4840 - accuracy: 0.7968 - val_loss: 0.7939 - val_accuracy: 0.6667\nEpoch 119/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.5112 - accuracy: 0.7487 - val_loss: 0.7959 - val_accuracy: 0.6667\nEpoch 120/290\n5/5 [==============================] - 0s 11ms/step - loss: 0.4579 - accuracy: 0.7647 - val_loss: 0.7990 - val_accuracy: 0.6667\nEpoch 121/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.7861 - val_loss: 0.8016 - val_accuracy: 0.6667\nEpoch 122/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.7647 - val_loss: 0.8037 - val_accuracy: 0.6667\nEpoch 123/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.7754 - val_loss: 0.8052 - val_accuracy: 0.6667\nEpoch 124/290\n5/5 [==============================] - 0s 12ms/step - loss: 0.5107 - accuracy: 0.7594 - val_loss: 0.8070 - val_accuracy: 0.6667\nEpoch 125/290\n5/5 [==============================] - 0s 12ms/step - loss: 0.5038 - accuracy: 0.7701 - val_loss: 0.8085 - val_accuracy: 0.6667\nEpoch 126/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4831 - accuracy: 0.7487 - val_loss: 0.8097 - val_accuracy: 0.6667\nEpoch 127/290\n5/5 [==============================] - 0s 12ms/step - loss: 0.4811 - accuracy: 0.7647 - val_loss: 0.8109 - val_accuracy: 0.6667\nEpoch 128/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4710 - accuracy: 0.7594 - val_loss: 0.8125 - val_accuracy: 0.6667\nEpoch 129/290\n5/5 [==============================] - 0s 12ms/step - loss: 0.4823 - accuracy: 0.7861 - val_loss: 0.8138 - val_accuracy: 0.6667\nEpoch 130/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5091 - accuracy: 0.7754 - val_loss: 0.8149 - val_accuracy: 0.6667\nEpoch 131/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4797 - accuracy: 0.7540 - val_loss: 0.8163 - val_accuracy: 0.6667\nEpoch 132/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.7701 - val_loss: 0.8176 - val_accuracy: 0.6667\nEpoch 133/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4561 - accuracy: 0.7861 - val_loss: 0.8201 - val_accuracy: 0.6667\nEpoch 134/290\n5/5 [==============================] - 0s 11ms/step - loss: 0.5033 - accuracy: 0.7754 - val_loss: 0.8228 - val_accuracy: 0.6667\nEpoch 135/290\n5/5 [==============================] - 0s 17ms/step - loss: 0.4888 - accuracy: 0.7914 - val_loss: 0.8255 - val_accuracy: 0.6667\nEpoch 136/290\n5/5 [==============================] - 0s 12ms/step - loss: 0.4604 - accuracy: 0.7968 - val_loss: 0.8273 - val_accuracy: 0.6667\nEpoch 137/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4854 - accuracy: 0.7701 - val_loss: 0.8287 - val_accuracy: 0.6667\nEpoch 138/290\n5/5 [==============================] - 0s 11ms/step - loss: 0.5175 - accuracy: 0.7487 - val_loss: 0.8301 - val_accuracy: 0.6667\nEpoch 139/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4853 - accuracy: 0.7807 - val_loss: 0.8321 - val_accuracy: 0.6667\nEpoch 140/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4769 - accuracy: 0.7540 - val_loss: 0.8324 - val_accuracy: 0.6667\nEpoch 141/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.7487 - val_loss: 0.8337 - val_accuracy: 0.6667\nEpoch 142/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.5019 - accuracy: 0.7380 - val_loss: 0.8345 - val_accuracy: 0.6667\nEpoch 143/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.7754 - val_loss: 0.8365 - val_accuracy: 0.6667\nEpoch 144/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4901 - accuracy: 0.7861 - val_loss: 0.8392 - val_accuracy: 0.6667\nEpoch 145/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4568 - accuracy: 0.7861 - val_loss: 0.8401 - val_accuracy: 0.6667\nEpoch 146/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4602 - accuracy: 0.7647 - val_loss: 0.8418 - val_accuracy: 0.6667\nEpoch 147/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4785 - accuracy: 0.7540 - val_loss: 0.8443 - val_accuracy: 0.6667\nEpoch 148/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4919 - accuracy: 0.7540 - val_loss: 0.8459 - val_accuracy: 0.6667\nEpoch 149/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4466 - accuracy: 0.7914 - val_loss: 0.8473 - val_accuracy: 0.6667\nEpoch 150/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4654 - accuracy: 0.7754 - val_loss: 0.8485 - val_accuracy: 0.6667\nEpoch 151/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4897 - accuracy: 0.7914 - val_loss: 0.8495 - val_accuracy: 0.6667\nEpoch 152/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.7594 - val_loss: 0.8503 - val_accuracy: 0.6667\nEpoch 153/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4573 - accuracy: 0.7807 - val_loss: 0.8525 - val_accuracy: 0.6667\nEpoch 154/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4890 - accuracy: 0.7754 - val_loss: 0.8553 - val_accuracy: 0.6667\nEpoch 155/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4531 - accuracy: 0.7540 - val_loss: 0.8570 - val_accuracy: 0.6667\nEpoch 156/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.7914 - val_loss: 0.8597 - val_accuracy: 0.6667\nEpoch 157/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4252 - accuracy: 0.8075 - val_loss: 0.8623 - val_accuracy: 0.6667\nEpoch 158/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4626 - accuracy: 0.7647 - val_loss: 0.8658 - val_accuracy: 0.6667\nEpoch 159/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4893 - accuracy: 0.7433 - val_loss: 0.8686 - val_accuracy: 0.6667\nEpoch 160/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4375 - accuracy: 0.7540 - val_loss: 0.8709 - val_accuracy: 0.6667\nEpoch 161/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4674 - accuracy: 0.7594 - val_loss: 0.8733 - val_accuracy: 0.6667\nEpoch 162/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4496 - accuracy: 0.7754 - val_loss: 0.8768 - val_accuracy: 0.6667\nEpoch 163/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.7861 - val_loss: 0.8807 - val_accuracy: 0.6667\nEpoch 164/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4545 - accuracy: 0.7701 - val_loss: 0.8843 - val_accuracy: 0.6667\nEpoch 165/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.7594 - val_loss: 0.8883 - val_accuracy: 0.6667\nEpoch 166/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4650 - accuracy: 0.7914 - val_loss: 0.8917 - val_accuracy: 0.6667\nEpoch 167/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4351 - accuracy: 0.7754 - val_loss: 0.8952 - val_accuracy: 0.6508\nEpoch 168/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.7701 - val_loss: 0.8996 - val_accuracy: 0.6508\nEpoch 169/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4601 - accuracy: 0.7807 - val_loss: 0.9021 - val_accuracy: 0.6508\nEpoch 170/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4783 - accuracy: 0.7433 - val_loss: 0.9047 - val_accuracy: 0.6508\nEpoch 171/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4465 - accuracy: 0.7807 - val_loss: 0.9087 - val_accuracy: 0.6508\nEpoch 172/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4441 - accuracy: 0.7861 - val_loss: 0.9110 - val_accuracy: 0.6349\nEpoch 173/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4828 - accuracy: 0.7433 - val_loss: 0.9123 - val_accuracy: 0.6349\nEpoch 174/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4432 - accuracy: 0.7861 - val_loss: 0.9148 - val_accuracy: 0.6349\nEpoch 175/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4247 - accuracy: 0.7754 - val_loss: 0.9188 - val_accuracy: 0.6349\nEpoch 176/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4461 - accuracy: 0.7647 - val_loss: 0.9225 - val_accuracy: 0.6349\nEpoch 177/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4752 - accuracy: 0.7754 - val_loss: 0.9254 - val_accuracy: 0.6349\nEpoch 178/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4137 - accuracy: 0.7807 - val_loss: 0.9278 - val_accuracy: 0.6508\nEpoch 179/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4185 - accuracy: 0.7701 - val_loss: 0.9321 - val_accuracy: 0.6508\nEpoch 180/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4618 - accuracy: 0.7647 - val_loss: 0.9363 - val_accuracy: 0.6508\nEpoch 181/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4336 - accuracy: 0.7540 - val_loss: 0.9402 - val_accuracy: 0.6508\nEpoch 182/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.7861 - val_loss: 0.9421 - val_accuracy: 0.6508\nEpoch 183/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4306 - accuracy: 0.7647 - val_loss: 0.9441 - val_accuracy: 0.6508\nEpoch 184/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4316 - accuracy: 0.7701 - val_loss: 0.9458 - val_accuracy: 0.6508\nEpoch 185/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4170 - accuracy: 0.8128 - val_loss: 0.9490 - val_accuracy: 0.6508\nEpoch 186/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4348 - accuracy: 0.7754 - val_loss: 0.9524 - val_accuracy: 0.6508\nEpoch 187/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.7968 - val_loss: 0.9567 - val_accuracy: 0.6508\nEpoch 188/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.7380 - val_loss: 0.9610 - val_accuracy: 0.6508\nEpoch 189/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4478 - accuracy: 0.7861 - val_loss: 0.9633 - val_accuracy: 0.6508\nEpoch 190/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4511 - accuracy: 0.7487 - val_loss: 0.9650 - val_accuracy: 0.6508\nEpoch 191/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4199 - accuracy: 0.7968 - val_loss: 0.9665 - val_accuracy: 0.6508\nEpoch 192/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4415 - accuracy: 0.7861 - val_loss: 0.9690 - val_accuracy: 0.6508\nEpoch 193/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4209 - accuracy: 0.8075 - val_loss: 0.9702 - val_accuracy: 0.6508\nEpoch 194/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4498 - accuracy: 0.7861 - val_loss: 0.9699 - val_accuracy: 0.6667\nEpoch 195/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4522 - accuracy: 0.7540 - val_loss: 0.9701 - val_accuracy: 0.6667\nEpoch 196/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4419 - accuracy: 0.7754 - val_loss: 0.9720 - val_accuracy: 0.6667\nEpoch 197/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4110 - accuracy: 0.7754 - val_loss: 0.9739 - val_accuracy: 0.6667\nEpoch 198/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.7968 - val_loss: 0.9771 - val_accuracy: 0.6667\nEpoch 199/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4437 - accuracy: 0.7861 - val_loss: 0.9810 - val_accuracy: 0.6667\nEpoch 200/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.7701 - val_loss: 0.9853 - val_accuracy: 0.6667\nEpoch 201/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.7968 - val_loss: 0.9888 - val_accuracy: 0.6667\nEpoch 202/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4237 - accuracy: 0.7754 - val_loss: 0.9930 - val_accuracy: 0.6667\nEpoch 203/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3900 - accuracy: 0.8075 - val_loss: 0.9985 - val_accuracy: 0.6667\nEpoch 204/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4364 - accuracy: 0.7701 - val_loss: 1.0030 - val_accuracy: 0.6667\nEpoch 205/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4435 - accuracy: 0.7754 - val_loss: 1.0062 - val_accuracy: 0.6667\nEpoch 206/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4637 - accuracy: 0.7540 - val_loss: 1.0078 - val_accuracy: 0.6667\nEpoch 207/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.7968 - val_loss: 1.0093 - val_accuracy: 0.6667\nEpoch 208/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4685 - accuracy: 0.7594 - val_loss: 1.0112 - val_accuracy: 0.6667\nEpoch 209/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.7701 - val_loss: 1.0132 - val_accuracy: 0.6667\nEpoch 210/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4134 - accuracy: 0.7914 - val_loss: 1.0155 - val_accuracy: 0.6667\nEpoch 211/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4071 - accuracy: 0.7807 - val_loss: 1.0199 - val_accuracy: 0.6667\nEpoch 212/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4381 - accuracy: 0.7701 - val_loss: 1.0219 - val_accuracy: 0.6667\nEpoch 213/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.7701 - val_loss: 1.0251 - val_accuracy: 0.6667\nEpoch 214/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4064 - accuracy: 0.8289 - val_loss: 1.0308 - val_accuracy: 0.6667\nEpoch 215/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.7914 - val_loss: 1.0352 - val_accuracy: 0.6667\nEpoch 216/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4122 - accuracy: 0.8128 - val_loss: 1.0394 - val_accuracy: 0.6667\nEpoch 217/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4248 - accuracy: 0.8075 - val_loss: 1.0439 - val_accuracy: 0.6667\nEpoch 218/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.7861 - val_loss: 1.0487 - val_accuracy: 0.6508\nEpoch 219/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4284 - accuracy: 0.7914 - val_loss: 1.0524 - val_accuracy: 0.6508\nEpoch 220/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4212 - accuracy: 0.7701 - val_loss: 1.0554 - val_accuracy: 0.6667\nEpoch 221/290\n5/5 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.7914 - val_loss: 1.0581 - val_accuracy: 0.6667\nEpoch 222/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3998 - accuracy: 0.7914 - val_loss: 1.0625 - val_accuracy: 0.6508\nEpoch 223/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4127 - accuracy: 0.7807 - val_loss: 1.0663 - val_accuracy: 0.6508\nEpoch 224/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3993 - accuracy: 0.7861 - val_loss: 1.0716 - val_accuracy: 0.6508\nEpoch 225/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.8182 - val_loss: 1.0743 - val_accuracy: 0.6508\nEpoch 226/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4493 - accuracy: 0.7594 - val_loss: 1.0761 - val_accuracy: 0.6508\nEpoch 227/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3853 - accuracy: 0.8235 - val_loss: 1.0804 - val_accuracy: 0.6349\nEpoch 228/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 1.0845 - val_accuracy: 0.6349\nEpoch 229/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 1.0860 - val_accuracy: 0.6508\nEpoch 230/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3511 - accuracy: 0.8342 - val_loss: 1.0893 - val_accuracy: 0.6349\nEpoch 231/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4337 - accuracy: 0.7647 - val_loss: 1.0917 - val_accuracy: 0.6349\nEpoch 232/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4016 - accuracy: 0.8128 - val_loss: 1.0942 - val_accuracy: 0.6349\nEpoch 233/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.7861 - val_loss: 1.0956 - val_accuracy: 0.6508\nEpoch 234/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4318 - accuracy: 0.7594 - val_loss: 1.1006 - val_accuracy: 0.6508\nEpoch 235/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4140 - accuracy: 0.7968 - val_loss: 1.1051 - val_accuracy: 0.6508\nEpoch 236/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.3971 - accuracy: 0.7861 - val_loss: 1.1092 - val_accuracy: 0.6508\nEpoch 237/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8021 - val_loss: 1.1117 - val_accuracy: 0.6508\nEpoch 238/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.7914 - val_loss: 1.1142 - val_accuracy: 0.6508\nEpoch 239/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4021 - accuracy: 0.7754 - val_loss: 1.1157 - val_accuracy: 0.6508\nEpoch 240/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.3996 - accuracy: 0.7754 - val_loss: 1.1193 - val_accuracy: 0.6349\nEpoch 241/290\n5/5 [==============================] - 0s 11ms/step - loss: 0.3958 - accuracy: 0.8235 - val_loss: 1.1228 - val_accuracy: 0.6349\nEpoch 242/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4096 - accuracy: 0.8075 - val_loss: 1.1249 - val_accuracy: 0.6349\nEpoch 243/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3999 - accuracy: 0.7968 - val_loss: 1.1281 - val_accuracy: 0.6349\nEpoch 244/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3635 - accuracy: 0.8182 - val_loss: 1.1343 - val_accuracy: 0.6349\nEpoch 245/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3755 - accuracy: 0.7807 - val_loss: 1.1428 - val_accuracy: 0.6349\nEpoch 246/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4173 - accuracy: 0.7861 - val_loss: 1.1516 - val_accuracy: 0.6508\nEpoch 247/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4046 - accuracy: 0.8021 - val_loss: 1.1549 - val_accuracy: 0.6349\nEpoch 248/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3972 - accuracy: 0.8342 - val_loss: 1.1587 - val_accuracy: 0.6349\nEpoch 249/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3858 - accuracy: 0.8021 - val_loss: 1.1635 - val_accuracy: 0.6349\nEpoch 250/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4193 - accuracy: 0.7861 - val_loss: 1.1686 - val_accuracy: 0.6349\nEpoch 251/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.7647 - val_loss: 1.1742 - val_accuracy: 0.6667\nEpoch 252/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8075 - val_loss: 1.1802 - val_accuracy: 0.6667\nEpoch 253/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.7861 - val_loss: 1.1875 - val_accuracy: 0.6667\nEpoch 254/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4126 - accuracy: 0.7861 - val_loss: 1.1914 - val_accuracy: 0.6667\nEpoch 255/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3470 - accuracy: 0.8289 - val_loss: 1.1936 - val_accuracy: 0.6667\nEpoch 256/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4083 - accuracy: 0.7914 - val_loss: 1.1952 - val_accuracy: 0.6667\nEpoch 257/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.8075 - val_loss: 1.1991 - val_accuracy: 0.6667\nEpoch 258/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3894 - accuracy: 0.7754 - val_loss: 1.2031 - val_accuracy: 0.6667\nEpoch 259/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4067 - accuracy: 0.7861 - val_loss: 1.2073 - val_accuracy: 0.6508\nEpoch 260/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.8075 - val_loss: 1.2101 - val_accuracy: 0.6508\nEpoch 261/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3834 - accuracy: 0.8128 - val_loss: 1.2155 - val_accuracy: 0.6508\nEpoch 262/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.7701 - val_loss: 1.2232 - val_accuracy: 0.6508\nEpoch 263/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3739 - accuracy: 0.8128 - val_loss: 1.2296 - val_accuracy: 0.6508\nEpoch 264/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4169 - accuracy: 0.7861 - val_loss: 1.2352 - val_accuracy: 0.6508\nEpoch 265/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3665 - accuracy: 0.8075 - val_loss: 1.2389 - val_accuracy: 0.6508\nEpoch 266/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4134 - accuracy: 0.7754 - val_loss: 1.2446 - val_accuracy: 0.6667\nEpoch 267/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.7701 - val_loss: 1.2505 - val_accuracy: 0.6667\nEpoch 268/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3788 - accuracy: 0.8021 - val_loss: 1.2539 - val_accuracy: 0.6667\nEpoch 269/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3829 - accuracy: 0.8021 - val_loss: 1.2597 - val_accuracy: 0.6667\nEpoch 270/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3978 - accuracy: 0.8075 - val_loss: 1.2657 - val_accuracy: 0.6667\nEpoch 271/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3644 - accuracy: 0.8396 - val_loss: 1.2700 - val_accuracy: 0.6508\nEpoch 272/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3735 - accuracy: 0.7968 - val_loss: 1.2728 - val_accuracy: 0.6508\nEpoch 273/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4009 - accuracy: 0.7754 - val_loss: 1.2732 - val_accuracy: 0.6508\nEpoch 274/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3919 - accuracy: 0.8075 - val_loss: 1.2696 - val_accuracy: 0.6508\nEpoch 275/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3617 - accuracy: 0.8075 - val_loss: 1.2715 - val_accuracy: 0.6508\nEpoch 276/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3890 - accuracy: 0.8075 - val_loss: 1.2758 - val_accuracy: 0.6508\nEpoch 277/290\n5/5 [==============================] - 0s 9ms/step - loss: 0.3685 - accuracy: 0.8182 - val_loss: 1.2830 - val_accuracy: 0.6508\nEpoch 278/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3313 - accuracy: 0.8182 - val_loss: 1.2906 - val_accuracy: 0.6508\nEpoch 279/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3697 - accuracy: 0.7807 - val_loss: 1.2968 - val_accuracy: 0.6508\nEpoch 280/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.4039 - accuracy: 0.7861 - val_loss: 1.3016 - val_accuracy: 0.6508\nEpoch 281/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3597 - accuracy: 0.8342 - val_loss: 1.3052 - val_accuracy: 0.6508\nEpoch 282/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3823 - accuracy: 0.8021 - val_loss: 1.3102 - val_accuracy: 0.6508\nEpoch 283/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.3179 - accuracy: 0.8503 - val_loss: 1.3160 - val_accuracy: 0.6508\nEpoch 284/290\n5/5 [==============================] - 0s 11ms/step - loss: 0.3646 - accuracy: 0.8075 - val_loss: 1.3226 - val_accuracy: 0.6508\nEpoch 285/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.8342 - val_loss: 1.3322 - val_accuracy: 0.6349\nEpoch 286/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3910 - accuracy: 0.8021 - val_loss: 1.3385 - val_accuracy: 0.6349\nEpoch 287/290\n5/5 [==============================] - 0s 14ms/step - loss: 0.3644 - accuracy: 0.7861 - val_loss: 1.3413 - val_accuracy: 0.6349\nEpoch 288/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3448 - accuracy: 0.8449 - val_loss: 1.3477 - val_accuracy: 0.6349\nEpoch 289/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3405 - accuracy: 0.8342 - val_loss: 1.3555 - val_accuracy: 0.6349\nEpoch 290/290\n5/5 [==============================] - 0s 10ms/step - loss: 0.3600 - accuracy: 0.7968 - val_loss: 1.3641 - val_accuracy: 0.6349\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:58:40.557873Z","iopub.execute_input":"2023-03-16T12:58:40.558744Z","iopub.status.idle":"2023-03-16T12:58:41.987072Z","shell.execute_reply.started":"2023-03-16T12:58:40.558687Z","shell.execute_reply":"2023-03-16T12:58:41.985952Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"618/618 [==============================] - 1s 1ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:58:52.734329Z","iopub.execute_input":"2023-03-16T12:58:52.734801Z","iopub.status.idle":"2023-03-16T12:58:52.743413Z","shell.execute_reply.started":"2023-03-16T12:58:52.734757Z","shell.execute_reply":"2023-03-16T12:58:52.742058Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[0.14265068],\n       [0.62688476],\n       [0.509202  ],\n       ...,\n       [0.13116474],\n       [0.54472274],\n       [0.26901475]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"result = pd.read_csv('/kaggle/input/dont-overfit-ii/sample_submission.csv')\nresult['target'] = predictions\nresult.to_csv('submission11.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T12:59:17.040415Z","iopub.execute_input":"2023-03-16T12:59:17.040867Z","iopub.status.idle":"2023-03-16T12:59:17.092524Z","shell.execute_reply.started":"2023-03-16T12:59:17.040827Z","shell.execute_reply":"2023-03-16T12:59:17.091575Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}